{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#설정\n",
    "# 파이썬 2와 파이썬 3 지원\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# 공통\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# 맷플롯립 설정\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "plt.rcParams['font.family'] = 'NanumBarunGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 그림을 저장할 폴더\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래디언트 소실, 폭주 문제\n",
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py:1328: UserWarning: findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('convergence', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('convergence',xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"logistic activation fumnction\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#xavier & he 초기화\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.variance_scaling_initializer() #he 초기화 이용\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, #tf.layers.dense는 기본적으로 xavier초기화를 이용한다.\n",
    "                          kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#수렴하지 않는 활성화 함수(죽은 ReLu문제 해결)\n",
    "#Leaky ReLU\n",
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py:1328: UserWarning: findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('pass', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서플로에서 Leaky ReLU 구현하기\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\") #leaky_relu를 활성함수로 이용하는 은닉층 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relu를 이용하여 신경망 훈련시키기\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로드하기\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 데이터 정확도: 0.86 검증 세트 정확도: 0.9018\n",
      "5 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9474\n",
      "10 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.964\n",
      "15 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.971\n",
      "20 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9738\n",
      "25 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9772\n",
      "30 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9784\n",
      "35 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9784\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"배치 데이터 정확도:\", acc_batch, \"검증 세트 정확도:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELU\n",
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py:1328: UserWarning: findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow에서 구현\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELU(성능이 가장 좋음)\n",
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * elu(z, alpha)\n",
    "''''\n",
    "이 활성화 함수는 Günter Klambauer, Thomas Unterthiner, Andreas Mayr가 2017년에 쓴 논문에서 소개되었습니다\n",
    "(나중에 책에 추가하겠습니다). 훈련할 때 SELU 활성화 함수를 사용한 완전 연결 신경망은 스스로 정규화를 합니다.\n",
    "각 층의 출력은 훈련하는 동안 같은 평균과 분산을 유지하려는 경향이 있어 그래디언트 소실과 폭주 문제를 해결합니다. \n",
    "이 활성화 함수는 심층 신경망에서 다른 활성화 함수보다 뛰어난 성능을 내므로 꼭 이 함수를 시도해봐야 합니다.\n",
    "''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py:1328: UserWarning: findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.show()\n",
    "''''\n",
    "기본적으로 SELU 하이퍼파라미터(scale과 alpha)는 평균이 0, 표준 편차가 1에 가깝게 유지되도록 조정합니다\n",
    "(입력도 평균이 0, 표준 편차가 1로 표준화되었다고 가정합니다). \n",
    "활성화 함수를 사용하면 100층으로 된 심층 신경망도 그래디언트 소실/폭주 문제없이 모든 층에서 대략 평균이 0이고 표준 편차가 1을 유지합니다:\n",
    "''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "층 0: -0.26 < 평균 < 0.27, 0.74 < 표준 편차 < 1.27\n",
      "층 10: -0.24 < 평균 < 0.27, 0.74 < 표준 편차 < 1.27\n",
      "층 20: -0.17 < 평균 < 0.18, 0.74 < 표준 편차 < 1.24\n",
      "층 30: -0.27 < 평균 < 0.24, 0.78 < 표준 편차 < 1.20\n",
      "층 40: -0.38 < 평균 < 0.39, 0.74 < 표준 편차 < 1.25\n",
      "층 50: -0.27 < 평균 < 0.31, 0.73 < 표준 편차 < 1.27\n",
      "층 60: -0.26 < 평균 < 0.43, 0.74 < 표준 편차 < 1.35\n",
      "층 70: -0.19 < 평균 < 0.21, 0.75 < 표준 편차 < 1.21\n",
      "층 80: -0.18 < 평균 < 0.16, 0.72 < 표준 편차 < 1.19\n",
      "층 90: -0.19 < 평균 < 0.16, 0.75 < 표준 편차 < 1.20\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100))\n",
    "for layer in range(100):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1/100))\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=1)\n",
    "    stds = np.std(Z, axis=1)\n",
    "    if layer % 10 == 0:\n",
    "        print(\"층 {}: {:.2f} < 평균 < {:.2f}, {:.2f} < 표준 편차 < {:.2f}\".format(\n",
    "            layer, means.min(), means.max(), stds.min(), stds.max())) #다층 신경망에서도 표준편차와 평균을 유지해 그래디언트 소실과 폭주를 잡아줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELU를 이용한 MNIST 분류\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = X_train.mean(axis=0, keepdims=True)\n",
    "stds = X_train.std(axis=0, keepdims=True) + 1e-10\n",
    "X_val_scaled = (X_valid - means) / stds\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch_scaled = (X_batch - means) / stds #스케일 조정을 해줘야함\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_val_scaled, y: y_valid})\n",
    "            print(epoch, \"배치 데이터 정확도:\", acc_batch, \"검증 세트 정확도:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final_selu.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#배치 정규화\n",
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#반복을 줄이기 위한 python의 partial 함수\n",
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 층에 ELU 활성화 함수와 배치 정규화를 사용하여 MNIST를 위한 신경망을 만듦\n",
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#배치 정규화를 위해 별도의 업데이트 연산을 실행\n",
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9096\n",
      "1 검증 세트 정확도: 0.9308\n",
      "2 검증 세트 정확도: 0.942\n",
      "3 검증 세트 정확도: 0.9524\n",
      "4 검증 세트 정확도: 0.9566\n",
      "5 검증 세트 정확도: 0.9612\n",
      "6 검증 세트 정확도: 0.9622\n",
      "7 검증 세트 정확도: 0.9648\n",
      "8 검증 세트 정확도: 0.965\n",
      "9 검증 세트 정확도: 0.9682\n",
      "10 검증 세트 정확도: 0.9676\n",
      "11 검증 세트 정확도: 0.969\n",
      "12 검증 세트 정확도: 0.9698\n",
      "13 검증 세트 정확도: 0.9698\n",
      "14 검증 세트 정확도: 0.9726\n",
      "15 검증 세트 정확도: 0.9726\n",
      "16 검증 세트 정확도: 0.9734\n",
      "17 검증 세트 정확도: 0.9738\n",
      "18 검증 세트 정확도: 0.9752\n",
      "19 검증 세트 정확도: 0.9756\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops], #이동 평균 갱신을 위한 연산 실행\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch}) #training을 True로 지정\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#경사하강법 연산에 업데이트 연산 추가하기\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9096\n",
      "1 검증 세트 정확도: 0.9286\n",
      "2 검증 세트 정확도: 0.9424\n",
      "3 검증 세트 정확도: 0.9518\n",
      "4 검증 세트 정확도: 0.9574\n",
      "5 검증 세트 정확도: 0.9602\n",
      "6 검증 세트 정확도: 0.9624\n",
      "7 검증 세트 정확도: 0.9646\n",
      "8 검증 세트 정확도: 0.9642\n",
      "9 검증 세트 정확도: 0.9664\n",
      "10 검증 세트 정확도: 0.9676\n",
      "11 검증 세트 정확도: 0.9692\n",
      "12 검증 세트 정확도: 0.9706\n",
      "13 검증 세트 정확도: 0.9702\n",
      "14 검증 세트 정확도: 0.971\n",
      "15 검증 세트 정확도: 0.9738\n",
      "16 검증 세트 정확도: 0.9744\n",
      "17 검증 세트 정확도: 0.9744\n",
      "18 검증 세트 정확도: 0.9768\n",
      "19 검증 세트 정확도: 0.9764\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch}) #training을 True로 지정\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련에 따라 업데이트 되는 변수\n",
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전체 변수\n",
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래디언트 클리핑(그래디언트 폭주 문제 해결을 위해 일정 임계값을 넘어가지 못하게 그래디언트를 절단)\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래디언트 클리핑 적용\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss) #그래디언트 계산\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var) #그래디언트 클리핑\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs) #그래디언트 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.5088\n",
      "1 검증 세트 정확도: 0.8334\n",
      "2 검증 세트 정확도: 0.8888\n",
      "3 검증 세트 정확도: 0.9094\n",
      "4 검증 세트 정확도: 0.9194\n",
      "5 검증 세트 정확도: 0.9224\n",
      "6 검증 세트 정확도: 0.9326\n",
      "7 검증 세트 정확도: 0.9388\n",
      "8 검증 세트 정확도: 0.94\n",
      "9 검증 세트 정확도: 0.9444\n",
      "10 검증 세트 정확도: 0.9484\n",
      "11 검증 세트 정확도: 0.9486\n",
      "12 검증 세트 정확도: 0.9512\n",
      "13 검증 세트 정확도: 0.956\n",
      "14 검증 세트 정확도: 0.9548\n",
      "15 검증 세트 정확도: 0.9588\n",
      "16 검증 세트 정확도: 0.9614\n",
      "17 검증 세트 정확도: 0.9606\n",
      "18 검증 세트 정확도: 0.963\n",
      "19 검증 세트 정확도: 0.9628\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tensorflow 모델 재사용하기\n",
    "#그래프 구조를 로드해야 합니다. \n",
    "#import_meta_graph() 함수가 그래프 연산들을 로드하여 기본 그래프에 적재하고 모델의 상태를 복원할 수 있도록 Saver 객체를 반환합니다. \n",
    "#기본적으로 Saver 객체는 .meta 확장자를 가진 파일에 그래프 구조를 저장하므로 이 파일을 로드해야 합니다\n",
    "reset_graph()\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros/shape_as_tensor\n",
      "hidden1/bias/Initializer/zeros/Const\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros/shape_as_tensor\n",
      "hidden2/bias/Initializer/zeros/Const\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros/shape_as_tensor\n",
      "hidden3/bias/Initializer/zeros/Const\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros/shape_as_tensor\n",
      "hidden4/bias/Initializer/zeros/Const\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros/shape_as_tensor\n",
      "hidden5/bias/Initializer/zeros/Const\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros/shape_as_tensor\n",
      "outputs/bias/Initializer/zeros/Const\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "gradients/Shape\n",
      "gradients/grad_ys_0\n",
      "gradients/Fill\n",
      "gradients/loss/loss_grad/Reshape/shape\n",
      "gradients/loss/loss_grad/Reshape\n",
      "gradients/loss/loss_grad/Shape\n",
      "gradients/loss/loss_grad/Tile\n",
      "gradients/loss/loss_grad/Shape_1\n",
      "gradients/loss/loss_grad/Shape_2\n",
      "gradients/loss/loss_grad/Const\n",
      "gradients/loss/loss_grad/Prod\n",
      "gradients/loss/loss_grad/Const_1\n",
      "gradients/loss/loss_grad/Prod_1\n",
      "gradients/loss/loss_grad/Maximum/y\n",
      "gradients/loss/loss_grad/Maximum\n",
      "gradients/loss/loss_grad/floordiv\n",
      "gradients/loss/loss_grad/Cast\n",
      "gradients/loss/loss_grad/truediv\n",
      "gradients/zeros_like\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "clip_by_value/Minimum/y\n",
      "clip_by_value/Minimum\n",
      "clip_by_value/y\n",
      "clip_by_value\n",
      "clip_by_value_1/Minimum/y\n",
      "clip_by_value_1/Minimum\n",
      "clip_by_value_1/y\n",
      "clip_by_value_1\n",
      "clip_by_value_2/Minimum/y\n",
      "clip_by_value_2/Minimum\n",
      "clip_by_value_2/y\n",
      "clip_by_value_2\n",
      "clip_by_value_3/Minimum/y\n",
      "clip_by_value_3/Minimum\n",
      "clip_by_value_3/y\n",
      "clip_by_value_3\n",
      "clip_by_value_4/Minimum/y\n",
      "clip_by_value_4/Minimum\n",
      "clip_by_value_4/y\n",
      "clip_by_value_4\n",
      "clip_by_value_5/Minimum/y\n",
      "clip_by_value_5/Minimum\n",
      "clip_by_value_5/y\n",
      "clip_by_value_5\n",
      "clip_by_value_6/Minimum/y\n",
      "clip_by_value_6/Minimum\n",
      "clip_by_value_6/y\n",
      "clip_by_value_6\n",
      "clip_by_value_7/Minimum/y\n",
      "clip_by_value_7/Minimum\n",
      "clip_by_value_7/y\n",
      "clip_by_value_7\n",
      "clip_by_value_8/Minimum/y\n",
      "clip_by_value_8/Minimum\n",
      "clip_by_value_8/y\n",
      "clip_by_value_8\n",
      "clip_by_value_9/Minimum/y\n",
      "clip_by_value_9/Minimum\n",
      "clip_by_value_9/y\n",
      "clip_by_value_9\n",
      "clip_by_value_10/Minimum/y\n",
      "clip_by_value_10/Minimum\n",
      "clip_by_value_10/y\n",
      "clip_by_value_10\n",
      "clip_by_value_11/Minimum/y\n",
      "clip_by_value_11/Minimum\n",
      "clip_by_value_11/y\n",
      "clip_by_value_11\n",
      "GradientDescent/learning_rate\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/Assign_3\n",
      "save/Assign_4\n",
      "save/Assign_5\n",
      "save/Assign_6\n",
      "save/Assign_7\n",
      "save/Assign_8\n",
      "save/Assign_9\n",
      "save/Assign_10\n",
      "save/Assign_11\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "#해당 그래프의 모든 연산자 출력\n",
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 연산 추출\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#중요한 연산들을 모아놓은 colloection 만들기\n",
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"my_important_ops\", op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colloection 가져오기\n",
    "X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "#모델 복원\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9644\n",
      "1 검증 세트 정확도: 0.9646\n",
      "2 검증 세트 정확도: 0.9628\n",
      "3 검증 세트 정확도: 0.9658\n",
      "4 검증 세트 정확도: 0.9672\n",
      "5 검증 세트 정확도: 0.9656\n",
      "6 검증 세트 정확도: 0.9682\n",
      "7 검증 세트 정확도: 0.9678\n",
      "8 검증 세트 정확도: 0.9678\n",
      "9 검증 세트 정확도: 0.9688\n",
      "10 검증 세트 정확도: 0.97\n",
      "11 검증 세트 정확도: 0.9708\n",
      "12 검증 세트 정확도: 0.9676\n",
      "13 검증 세트 정확도: 0.9692\n",
      "14 검증 세트 정확도: 0.9704\n",
      "15 검증 세트 정확도: 0.97\n",
      "16 검증 세트 정확도: 0.9714\n",
      "17 검증 세트 정확도: 0.9692\n",
      "18 검증 세트 정확도: 0.9694\n",
      "19 검증 세트 정확도: 0.972\n"
     ]
    }
   ],
   "source": [
    "#새로운 데이터로 훈련 시작\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import grapgh()를 이용한 그래프 재사용(python 코드를 알고 있을때 이용)\n",
    "#재사용할 그래프 생성(기존의 그래프 코드)\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9644\n",
      "1 검증 세트 정확도: 0.9646\n",
      "2 검증 세트 정확도: 0.9628\n",
      "3 검증 세트 정확도: 0.9658\n",
      "4 검증 세트 정확도: 0.9672\n",
      "5 검증 세트 정확도: 0.9656\n",
      "6 검증 세트 정확도: 0.9682\n",
      "7 검증 세트 정확도: 0.9678\n",
      "8 검증 세트 정확도: 0.9678\n",
      "9 검증 세트 정확도: 0.9688\n",
      "10 검증 세트 정확도: 0.97\n",
      "11 검증 세트 정확도: 0.9708\n",
      "12 검증 세트 정확도: 0.9676\n",
      "13 검증 세트 정확도: 0.9692\n",
      "14 검증 세트 정확도: 0.9704\n",
      "15 검증 세트 정확도: 0.97\n",
      "16 검증 세트 정확도: 0.9714\n",
      "17 검증 세트 정확도: 0.9692\n",
      "18 검증 세트 정확도: 0.9694\n",
      "19 검증 세트 정확도: 0.972\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import_meta_graph()를 이용한 그래프 재사용\n",
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 20  # 새 층\n",
    "n_outputs = 10  # 새 층\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\") #기존 그래프의 연산 가져오기\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden4/Relu:0\") #기존 그래프의 층 가져오기\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
    "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9234\n",
      "1 검증 세트 정확도: 0.9434\n",
      "2 검증 세트 정확도: 0.9516\n",
      "3 검증 세트 정확도: 0.9556\n",
      "4 검증 세트 정확도: 0.9604\n",
      "5 검증 세트 정확도: 0.957\n",
      "6 검증 세트 정확도: 0.962\n",
      "7 검증 세트 정확도: 0.9624\n",
      "8 검증 세트 정확도: 0.9628\n",
      "9 검증 세트 정확도: 0.9636\n",
      "10 검증 세트 정확도: 0.966\n",
      "11 검증 세트 정확도: 0.9664\n",
      "12 검증 세트 정확도: 0.9642\n",
      "13 검증 세트 정확도: 0.967\n",
      "14 검증 세트 정확도: 0.9692\n",
      "15 검증 세트 정확도: 0.968\n",
      "16 검증 세트 정확도: 0.9694\n",
      "17 검증 세트 정확도: 0.968\n",
      "18 검증 세트 정확도: 0.9698\n",
      "19 검증 세트 정확도: 0.969\n"
     ]
    }
   ],
   "source": [
    "#모델 훈련\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본 모델과 비교\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # 재사용\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # 새로 만듦!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9076\n",
      "1 검증 세트 정확도: 0.9416\n",
      "2 검증 세트 정확도: 0.947\n",
      "3 검증 세트 정확도: 0.9528\n",
      "4 검증 세트 정확도: 0.9564\n",
      "5 검증 세트 정확도: 0.9578\n",
      "6 검증 세트 정확도: 0.958\n",
      "7 검증 세트 정확도: 0.9614\n",
      "8 검증 세트 정확도: 0.9606\n",
      "9 검증 세트 정확도: 0.9618\n",
      "10 검증 세트 정확도: 0.9638\n",
      "11 검증 세트 정확도: 0.967\n",
      "12 검증 세트 정확도: 0.9672\n",
      "13 검증 세트 정확도: 0.9682\n",
      "14 검증 세트 정확도: 0.9668\n",
      "15 검증 세트 정확도: 0.9674\n",
      "16 검증 세트 정확도: 0.968\n",
      "17 검증 세트 정확도: 0.9694\n",
      "18 검증 세트 정확도: 0.9676\n",
      "19 검증 세트 정확도: 0.9684\n"
     ]
    }
   ],
   "source": [
    "#이젠의 모델을 복원하기 위해 saver 객체를 하나 만들고 훈련이 끝나고 저장할 saver객체를 하나 만들어야 한다.\n",
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):                                        # 책에는 없음\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): # 책에는 없음\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})    # 책에는 없음\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                      # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "#다른 프레임워크의 모델 재사용하기\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3\n",
    "\n",
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # 다른 프레임워크로부터 가중치를 로드\n",
    "original_b = [7., 8., 9.]                 # 다른 프레임워크로부터 편향을 로드\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] 모델의 나머지 부분을 구성\n",
    "\n",
    "# hidden1 변수의 할당 노드에 대한 핸들을 구합니다\n",
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name(\"hidden1/kernel/Assign\")\n",
    "assign_bias = graph.get_operation_by_name(\"hidden1/bias/Assign\")\n",
    "init_kernel = assign_kernel.inputs[1]\n",
    "init_bias = assign_bias.inputs[1]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, feed_dict={init_kernel: original_w, init_bias: original_b})\n",
    "    # [...] 새 작업에 모델을 훈련시킵니다\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))  # 책에는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_collection()에 scope를 지정하여 변수의 핸들을 가져올 수도 있습니다\n",
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#또는 그래프의 get_tensor_by_name() 메서드를 사용할 수 있습니다\n",
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/bias:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하위층 동결하기\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # 재사용\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # 새로 만듦!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):                                         # 책에는 없음\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)     # 책에는 없음\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, # 은닉층 3,4에서 학습으로 변동될 변수들을 모두 구함\n",
    "                                   scope=\"hidden[34]|outputs\")\n",
    "    training_op = optimizer.minimize(loss, var_list=train_vars)  #위의 변수만 optimizer에 전달함으로 1,2층의 변수는 변동 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.902\n",
      "1 검증 세트 정확도: 0.9304\n",
      "2 검증 세트 정확도: 0.9386\n",
      "3 검증 세트 정확도: 0.941\n",
      "4 검증 세트 정확도: 0.9458\n",
      "5 검증 세트 정확도: 0.9488\n",
      "6 검증 세트 정확도: 0.9508\n",
      "7 검증 세트 정확도: 0.953\n",
      "8 검증 세트 정확도: 0.9534\n",
      "9 검증 세트 정확도: 0.9536\n",
      "10 검증 세트 정확도: 0.9552\n",
      "11 검증 세트 정확도: 0.9562\n",
      "12 검증 세트 정확도: 0.9544\n",
      "13 검증 세트 정확도: 0.9556\n",
      "14 검증 세트 정확도: 0.9558\n",
      "15 검증 세트 정확도: 0.9572\n",
      "16 검증 세트 정확도: 0.9574\n",
      "17 검증 세트 정확도: 0.9582\n",
      "18 검증 세트 정확도: 0.9584\n",
      "19 검증 세트 정확도: 0.9578\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규 표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#다른 방법\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # 동결층 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # 동결층 재사용\n",
    "    hidden2_stop = tf.stop_gradient(hidden2) #위의 층은 훈련시 변동이 없도록 고정\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # 동결하지 않고 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # 새로 만듦!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9176\n",
      "1 검증 세트 정확도: 0.9396\n",
      "2 검증 세트 정확도: 0.9478\n",
      "3 검증 세트 정확도: 0.9506\n",
      "4 검증 세트 정확도: 0.9516\n",
      "5 검증 세트 정확도: 0.9528\n",
      "6 검증 세트 정확도: 0.954\n",
      "7 검증 세트 정확도: 0.9554\n",
      "8 검증 세트 정확도: 0.9564\n",
      "9 검증 세트 정확도: 0.9572\n",
      "10 검증 세트 정확도: 0.9568\n",
      "11 검증 세트 정확도: 0.958\n",
      "12 검증 세트 정확도: 0.9578\n",
      "13 검증 세트 정확도: 0.9602\n",
      "14 검증 세트 정확도: 0.9588\n",
      "15 검증 세트 정확도: 0.9586\n",
      "16 검증 세트 정확도: 0.9594\n",
      "17 검증 세트 정확도: 0.9602\n",
      "18 검증 세트 정확도: 0.9608\n",
      "19 검증 세트 정확도: 0.9596\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규 표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##고속 옵티마이저\n",
    "#모멘텀 옵티마이저\n",
    "learning_rate = 0.1\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네스테로프 momentum optimizer\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaGrad(심층신경망외에 간단한 알고리즘에 사용)\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSProp\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n",
    "                                      momentum=0.9, decay=0.9, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam 최적화\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습률 스케쥴링\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):       # 책에는 없음\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                               decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.966\n",
      "1 검증 세트 정확도: 0.9746\n",
      "2 검증 세트 정확도: 0.9788\n",
      "3 검증 세트 정확도: 0.9812\n",
      "4 검증 세트 정확도: 0.9822\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##과대적합을 피하기 위한 방법\n",
    "#norm을 두어 규제 주기 (릿지와 라쏘의 개념)\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#층의 가중치에 대한 핸들을 얻어 크로스 엔트로피 손실에 l1 손실(즉, 가중치의 절댓값)을 더해 전체 손실을 계산\n",
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\") #연산이름 = hidden1, tensor이름은 kernel:0, 은닉층에 대한 가중치 핸들\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\") #출력에 대한 가중치 핸들\n",
    "\n",
    "scale = 0.001 # l1 규제 하이퍼파라미터\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.8282\n",
      "1 검증 세트 정확도: 0.8642\n",
      "2 검증 세트 정확도: 0.8822\n",
      "3 검증 세트 정확도: 0.8898\n",
      "4 검증 세트 정확도: 0.8946\n",
      "5 검증 세트 정확도: 0.898\n",
      "6 검증 세트 정확도: 0.9022\n",
      "7 검증 세트 정확도: 0.9044\n",
      "8 검증 세트 정확도: 0.9054\n",
      "9 검증 세트 정확도: 0.9072\n",
      "10 검증 세트 정확도: 0.9076\n",
      "11 검증 세트 정확도: 0.9098\n",
      "12 검증 세트 정확도: 0.9088\n",
      "13 검증 세트 정확도: 0.9088\n",
      "14 검증 세트 정확도: 0.9104\n",
      "15 검증 세트 정확도: 0.909\n",
      "16 검증 세트 정확도: 0.9086\n",
      "17 검증 세트 정확도: 0.908\n",
      "18 검증 세트 정확도: 0.9082\n",
      "19 검증 세트 정확도: 0.9062\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.layers.dense() 함수에 규제 함수를 전달할 수 있습니다. 이 함수는 규제 손실을 계산하기 위한 연산을 만들고 규제 손실 컬렉션에 이 연산을 추가\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#partial() 함수를 사용한 kernel_regularizer 매개변수를 지정(규제 함수 핸들을 하나하나 만들 필요가 없어짐)\n",
    "from functools import partial\n",
    "scale = 0.001\n",
    "\n",
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale)) #매개변수에 대한 기본값 지정(규제 가중치 추가), collection에 저장\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None,\n",
    "                            name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본 손실에 규제 손실을 추가\n",
    "with tf.name_scope(\"loss\"):                                     # 책에는 없음\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(  # 책에는 없음\n",
    "        labels=y, logits=logits)                                # 책에는 없음\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")   # 책에는 없음\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES) #저장된 규제 가져옴\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.8126\n",
      "1 검증 세트 정확도: 0.8702\n",
      "2 검증 세트 정확도: 0.8884\n",
      "3 검증 세트 정확도: 0.8982\n",
      "4 검증 세트 정확도: 0.902\n",
      "5 검증 세트 정확도: 0.9074\n",
      "6 검증 세트 정확도: 0.9088\n",
      "7 검증 세트 정확도: 0.9118\n",
      "8 검증 세트 정확도: 0.9126\n",
      "9 검증 세트 정확도: 0.9148\n",
      "10 검증 세트 정확도: 0.916\n",
      "11 검증 세트 정확도: 0.9162\n",
      "12 검증 세트 정확도: 0.9158\n",
      "13 검증 세트 정확도: 0.917\n",
      "14 검증 세트 정확도: 0.9176\n",
      "15 검증 세트 정확도: 0.9174\n",
      "16 검증 세트 정확도: 0.9172\n",
      "17 검증 세트 정확도: 0.9186\n",
      "18 검증 세트 정확도: 0.9186\n",
      "19 검증 세트 정확도: 0.9182\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#드롭아웃을 이용한 규제\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop out 적용\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5  # == 1 - keep_prob\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9264\n",
      "1 검증 세트 정확도: 0.9452\n",
      "2 검증 세트 정확도: 0.9554\n",
      "3 검증 세트 정확도: 0.9602\n",
      "4 검증 세트 정확도: 0.9668\n",
      "5 검증 세트 정확도: 0.9626\n",
      "6 검증 세트 정확도: 0.9648\n",
      "7 검증 세트 정확도: 0.9686\n",
      "8 검증 세트 정확도: 0.9694\n",
      "9 검증 세트 정확도: 0.973\n",
      "10 검증 세트 정확도: 0.9704\n",
      "11 검증 세트 정확도: 0.97\n",
      "12 검증 세트 정확도: 0.9742\n",
      "13 검증 세트 정확도: 0.9748\n",
      "14 검증 세트 정확도: 0.9774\n",
      "15 검증 세트 정확도: 0.9728\n",
      "16 검증 세트 정확도: 0.9768\n",
      "17 검증 세트 정확도: 0.9748\n",
      "18 검증 세트 정확도: 0.9764\n",
      "19 검증 세트 정확도: 0.9768\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max-norm regulation\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#다음으로 첫 번째 은닉층의 가중치에 대한 핸들을 얻고 clip_by_norm() 함수를 사용해 가중치를 클리핑하는 연산을 만듭니다. \n",
    "#그런 다음 클리핑된 가중치를 가중치 변수에 할당하는 연산을 만듭니다\n",
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\") #가중치에 대한 핸들 추추ㄹ\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)\n",
    "\n",
    "weights2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9576\n",
      "1 검증 세트 정확도: 0.9702\n",
      "2 검증 세트 정확도: 0.9696\n",
      "3 검증 세트 정확도: 0.9786\n",
      "4 검증 세트 정확도: 0.9766\n",
      "5 검증 세트 정확도: 0.9792\n",
      "6 검증 세트 정확도: 0.981\n",
      "7 검증 세트 정확도: 0.98\n",
      "8 검증 세트 정확도: 0.9792\n",
      "9 검증 세트 정확도: 0.9808\n",
      "10 검증 세트 정확도: 0.9806\n",
      "11 검증 세트 정확도: 0.982\n",
      "12 검증 세트 정확도: 0.9822\n",
      "13 검증 세트 정확도: 0.9832\n",
      "14 검증 세트 정확도: 0.9824\n",
      "15 검증 세트 정확도: 0.9832\n",
      "16 검증 세트 정확도: 0.9828\n",
      "17 검증 세트 정확도: 0.983\n",
      "18 검증 세트 정확도: 0.9824\n",
      "19 검증 세트 정확도: 0.983\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                              # 책에는 없음\n",
    "    init.run()                                                          # 책에는 없음\n",
    "    for epoch in range(n_epochs):                                       # 책에는 없음\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):  # 책에는 없음\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()  #매 스텝 마다 실행\n",
    "            clip_weights2.eval()                                        # 책에는 없음\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                     # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_norm_regularizer() 함수를 이용한 max-norm regulation\n",
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\",\n",
    "                         collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # 규제 손실을 위한 항이 없습니다\n",
    "    return max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\") #은닉충에 매개변수를 이용해서 전달\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9588\n",
      "1 검증 세트 정확도: 0.9716\n",
      "2 검증 세트 정확도: 0.97\n",
      "3 검증 세트 정확도: 0.9766\n",
      "4 검증 세트 정확도: 0.9754\n",
      "5 검증 세트 정확도: 0.9814\n",
      "6 검증 세트 정확도: 0.9802\n",
      "7 검증 세트 정확도: 0.98\n",
      "8 검증 세트 정확도: 0.9812\n",
      "9 검증 세트 정확도: 0.982\n",
      "10 검증 세트 정확도: 0.982\n",
      "11 검증 세트 정확도: 0.9844\n",
      "12 검증 세트 정확도: 0.9816\n",
      "13 검증 세트 정확도: 0.9826\n",
      "14 검증 세트 정확도: 0.9834\n",
      "15 검증 세트 정확도: 0.9836\n",
      "16 검증 세트 정확도: 0.9834\n",
      "17 검증 세트 정확도: 0.984\n",
      "18 검증 세트 정확도: 0.9834\n",
      "19 검증 세트 정확도: 0.9834\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights) #규제 실행\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                      # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
